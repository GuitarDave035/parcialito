import boto3
import requests
from datetime import datetime
from urllib.parse import urlencode


def lambda_handler(event, context):
    bucket_name = "parcial11"  # ğŸ“Œ Bucket de destino en S3
    base_url = "https://casas.mitula.com.co/find"
    s3 = boto3.client("s3")

    today = datetime.utcnow().strftime('%Y-%m-%d')
    file_key = f"landing-casas/{today}.html"  # ğŸ“Œ Nombre Ãºnico del archivo por dÃ­a

    all_pages_content = ""  # ğŸ“Œ Acumulador del contenido HTML

    for page in range(1, 11):  # ğŸ”¹ Descargar las primeras 10 pÃ¡ginas
        params = {
            "operationType": "sell",
            "propertyType": "mitula_studio_apartment",
            "geoId": "mitula-CO-poblacion-0000014156",
            "text": "BogotÃ¡,  (Cundinamarca)",
            "page": page
        }
        url = f"{base_url}?{urlencode(params)}"

        try:
            response = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=10)

            if response.status_code == 200:
                all_pages_content += f"\n<!-- PÃ¡gina {page} -->\n" + response.text
                print(f"âœ… PÃ¡gina {page} descargada correctamente.")
            else:
                print(f"âš ï¸ Error en pÃ¡gina {page}: {response.status_code}")

        except requests.RequestException as e:
            print(f"âŒ Error en la solicitud de la pÃ¡gina {page}: {e}")

    if not all_pages_content:
        print("ğŸš¨ No se descargÃ³ ninguna pÃ¡gina.")
        return {"status": "error", "message": "No se descargÃ³ ninguna pÃ¡gina"}

    # ğŸ“Œ Intentar subir a S3
    try:
        s3.put_object(
            Bucket=bucket_name,
            Key=file_key,
            Body=all_pages_content.encode("utf-8"),
            ContentType="text/html"
        )
        print(f"âœ… Archivo guardado en S3: s3://{bucket_name}/{file_key}")
        return {"status": "success", "file": f"s3://{bucket_name}/{file_key}"}

    except Exception as e:
        print(f"ğŸš¨ Error al subir a S3: {e}")
        return {"status": "error", "message": str(e)}
